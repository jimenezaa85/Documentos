Course Overview

Course Overview
Hi everyone. Welcome to the course Continuous Delivery and DevOps with TFS and VSTS 2018, Managing Builds. 
My name is Marcel de Vries, and I'm the chief technology officer at Xpirit in the Netherlands. 
Continuous Delivery and DevOps require you to fully automate the build and release process in a repeatable and reliable way. 
In this course, you will learn how to set up build automation in TFS or VSTS.

In module 1, we will start with the fundamentals and set up the build infrastructure enabling you to run your builds in a secure, fast, and reliable way. 
We will go through the concepts like build definitions, tasks, agents, queues, and pipelines to get you up to speed defining a build for your product. 

In module 2, I will give you the guidance around all the possible settings you can define in a build. 
We will look at concepts like build variables, managing secrets, retention policies, and selecting the tasks out-of-the-box or from the VSTS Marketplace. 
We'll look at how you optimize your builds by enabling you to run them in parallel, distributed across multiple agents. 

In module 3, we will look at important continuous delivery concepts, like configuration and Infrastructure as Code. 

We will look at how you can ensure that the configuration and infrastructure definitions become part of the build results and are placed in an artifact repository, ready to be handed off to the release process. 
After watching this course, you should be able to build your own software on a manage by Microsoft hosted build agents, or define your own custom agents on your own infrastructure. 
You understand when to use your own agent and how to secure the build servers to be used only by the teams you want. This course provides the building block to get continuous delivery set up, since the build is the starting point of your automation. I hope you join me on this learning journey with the course Continuous Delivery and DevOps with TFS and Visual Studio 2018, Managing Builds.

Build Fundamentals
Introduction
Welcome to the course continuous delivery and devops with TFS and VSTS 2018, Managing Builds. 
This is the starting module, build fundamentals. In this course, we will dive into the way that you can set up automated builds in Microsoft Team Foundation Server and Visual Studio Team Services 2018. I will learn you how to implement Continuous Integration, better known as CI, using the build automation tools. You will learn how CI builds produce the artifacts we need to move through the various quality checks before we move to production. My name is Marcel de Vries and I'm the Pluralsight author of this course. Please do not hesitate to reach out to me on Twitter @marcelv or use the Pluralsight discussion forum when you still have questions unanswered when taking this course. I will try to help you as soon as possible.

Outline
In this module fundamentals, we will start with the basics needed to understand using Team Foundation Server or Visual Studio Team Services build infrastructure. You will learn about the use terminology and how to set up a build to produce the artifacts you need for the product you build. In VSTS, you can build any software for any platform. After we discuss the fundamentals, we will look at the required build infrastructure. Depending on your needs, you can use the provided infrastructure in the cloud or set up your own infrastructure on-premises. When we have to write infrastructure in place, we then look how to set up build security. One of the things needed in continuous delivery is a reliable and secure build so we can ensure that our software is built according to compliance and security policies for our organization. We will end this module with looking at how to set up continuous integration builds. Those builds start after each commit or check in in your VSTS version control system of choice. Let's get started with the fundamentals right now.

Build Fundamentals
Before we can have a look at the way we configure a build system at Visual Studio Team Services or Team Foundation Server, let's first take a step back and see what a build system is and how it works. This way, we better understand how we should configure the system to fulfill our needs in the context of continuous delivery. Let's start with a definition of what a build system is. I searched for this on the internet to find a good definition of what a build system is, but I could not really find a nice and clean statement that describes what a build system does. So therefore, I decided to define it myself as a starting point so we have a common understanding going forward. A build system is a system used to automatically produce all the artifacts required to successfully deploy, test, and run our production software. In this definition, we can find that it's something that is done automatically, so no manual steps are involved in this process. We also prefer a system that can automatically trigger the builds, for example based on the fact that we commit new code to the source control system. The second part is that it produces all artifacts to successfully deploy, test, and run our production software. This means we're not only producing the production bits for our application, but we're also producing the artifacts to configure and set up the required application infrastructure and tests so we're all able to validate the software we build before we move into production. Important here is that we explicitly mean we also produce the artifacts we need to deploy our software, so our deployments are also defined in some form of code and used during deployment. This is a concept better known as configuration and infrastructure as code. Depending on the platform you're building for, you use various scripting technologies and templating languages. If you're working on Azure for example, you're using Azure Resource Manager templates. All these templates are coming from a source control system and the build is responsible for putting them in a place where we can get them from as one cohesive set of artifacts we use to put something into an environment.

Continuous Integration
Let us also define what continuous integration is since there's many confusion about this term as well. 
Continuous Integration, often referred to as simply CI, has been defined a long time ago by Grady Booch. 
He described continuous integration as a practice in software engineering of merging all developer working copies to a shared mainline several times a day. 
So this means we want to work is isolation on a local machine, but we want to commit our changes to the source control system as often as possible. 
We then also want to merge all these changes of all the developers into one main source control branch. 
I would like to add to the definition the concept of a continuous integration build. 
A continuous integration build is the fact that we build the integrated changes of our mainline by the means of a build server after each commit. 
Important part of the definition is that we integrate our changes constantly so we're not waiting all the time to queue them up and integrate them at a later point in time. This is because the longer you queue your changes, the harder it becomes to integrate them into the development branch. So while working in isolation is great, you must get back into the main development branch as soon as you can to ensure your merges are done in an easy way. The second thing is that the build server does the work all the time based on a trigger and this is the moment we commit a change to the source control system, so the builds are preferably triggered automatically and not manually. This combined with the previous definition ensures that we get the feedback on our work we have done constantly and it will give us an early warning what the quality of our changes are. This can all be found in the report coming from the build output.

How a Build Is Set Up
When we look at the VSTS build system, we need to start with a couple of terms that are used. 
First we start with the build definition. 
The definition defines the steps that need to be executed in order for us to get the required artifacts we can deploy, test, and run our code in production. This build definition is more or less a template that is used to run our build over and over again. Next, we need to understand the notion of a task or a build step. A task is some form of automation that takes an input and produces a new output that is useful for us. For example, we can have a task that compiles the source code. It takes the input, what sources to build and where to find them, and it produces a result like for example a set of DLLs or executables. The build definition defines the sequence in which we run the tasks and it defines variables that we can pass along between the different tasks. Finally, we have a build agent. The build agent executes the set of tasks for us and does the actual work. So the build definition and the tasks define what the build should do. The agent takes this information and starts executing the tasks in the sequence defined in the template and then produces the actual end result. Let's make this a little bit more concrete when defining a build in the following steps.

Selecting the Build Template, Source, Tasks, and Agent
When we create a new build definition, we first start by selecting either an empty process template or we use one of the predefined templates that come out of the box. Here you see a screenshot of this selection. You can see that we can run various sets of builds in VSTS. For example, you can build software for Android. You can also run for example an Ant or a Maven build for Java or for the Microsoft ecosystem and ASP.NET build that uses docker containers. This selection of predefined templates help you with a starting point. You can always change the steps that are part of the template in the later stage. Next, you need to select where the sources will come from. You can pick any of the external source control options like GitHub, Atlassian Bitbucket, Subversion, or an external host like Git Repository. The default is to use your VSTS project. This assumes you are using the source control provided by VSTS. This can either be Team Foundation Version Control or Git. When you select a repository, it will ask you which branch you want to build and if you want to enable continuous integration. This option will trigger a new build for every commit in your server repository. So if you are using Git, this will trigger a build for every push you do to the remote server to the selected branch or set of branches. Next, we need to configure what we're going to build. Here you see an example of the ASP.NET with containers I selected as a starting template. When you do this yourself, this template might have changed. These templates are constantly evolving and therefore can be different the moment you watch this course. The concept remains the same. On the left-hand side, you will see a set of tasks that define the task that need to be performed. On the right-hand side, you can configure the tasks you selected in the left pane. Depending on the selected step, you will see different configuration options specific to this task. Here you see the options for the Visual Studio build solution task as it is defined at the moment of this recording. Last but not least, we need to select on which agent we want to run this build. For this, I need to select a so called agent pool that I want to use. We will go in much more detail on agent pools later in this course, so for now it's good enough that we know that we select the Hosted Visual Studio 2017 pool to build a Visual Studio 2017 project. Instead of going through a configuration of a build in slides, let's just dive into a demo where I define a build for the ASP.NET MvcMusicStore application.

Configure and Run an ASP.NET build
In this demonstration, I'm going to show you how we can configure a build to build ASP.NET. Here you see that I have my Visual Studio team project and let's go to the source control. You see here that I have in my Git Repository the MvcMusicStore application. You see that I have my sources in here and I can also run this just from Visual Studio. You see the same structure is in here and I just have this on my desktop. Now we want to define a build for this. So for this, we go to the build and release option and then go to the build step. Here we can then go to add a new build definition and the moment we select this, we get the option to select from a template. So you see that there are various templates available so we can for example build Jenkins builds and we can do Maven builds and those kind of things so we can build anything for any platform. What we will do in this particular case is we will select an ASP.NET application and not the one with containers, but we will just take the one that is just only building our ASP.NET application. So let's click apply and this will generate a general structure on tasks that we need to run to build ASP.NET. Now first of all, we start with a process and we need to select the agent queue we're going to use to build agents. So for this, I'm going to select the Hosted VS2017 option and this gives me a pool of agents that have Visual Studio 2017 installed. I will change the name of this build so I can nicely look it up later. And the next thing that we will do is we will then have a look at the solution file. Now the solution file, we can link that as a variable into multiple tasks below, so this is just parameter defined essentially. I'm going to select this solution file because I hate to select just multiple things. I just want to be specific and I'm going to specify the drop location. Next, we need to select our source control provider and we selected Visual Studio Team Services in this case. You see that I have my Git Repository here and I only have a master branch that I selected to build. The next thing is that I can define agent phases. You can have multiple of these phases and for every phase you can define for example another agent queue if you want to. So for example, this is a way to switch between hosted and on-prem for specific tasks that you want to execute. Here you see the demands and I can demand that my agent has a certain set of capabilities, for example that it needs to have Visual Studio installed. The other thing is that we can then define if we want to run in parallel, but we will come to that in a later stage. Next, you see that if I click on the left-hand side any of these tasks, then you see that I have different parameters that I can set. And here for example for the build solution task, you see that there is a link to my solution variable that I defined when we started with this template, so this is where I picked my solution file over here so this one is linked to the build solution. The other thing that you see here is that we are building this software with a version of Visual Studio and this is the latest and I also defined some MSBuild Arguments to create a zip package that we can then deploy using Web Deploy. Here you see that you can then define also tests that you would like to run and these are normally unit tests that you would like to run. And if you look at control options, you can also define if a certain task needs to be executed, yes or no, or if there's an error that we need to continue on error, yes or no. Here you see the published symbols and then the last task is that we want to publish the artifact so the artifact repository that is part of our TFS server so here you see that we specify the TFS server as the artifact repository. Now it has a location and it's defined that it's on the server. Now this is the basic template. It's already defined everything that we need so we're going to save and queue this one. That means that we're saving the definition and we're going to queue a build right away. So when I click save and queue, you will see that we then get a link and we can click on this link and then watch what the build is actually doing. When you have a look at the build that's running, you can then actually follow along what the build is doing so you get all the information on the actual output of the agent. So here you see on the right-hand side that we have all the output coming from the agent and it's very detailed. Every step that's going to be executed is reported here back in your view. Now what I will do is I will fast forward this build a little bit. Otherwise, we're looking at a build for a very long time. You see that we're going through every step and every task is outputting information to our build window. And you can come in here any moment you want and you get this output and you can view it. Now once the build is done, which just takes a couple of seconds more and now we're done, you then see that we have a build report and in this build report I can then have a look at for example what are the steps that we've taken and how long did each step take, so this is a very nice way to see how we want to optimize our build. Now we also can go to another location here and that is the artifact location and here you see that we have the drop folder. And if I explore this, you can now see that in our drop location, we now have the output that was specified in my build solution where I wanted to have the zip package to run a Web Deploy on. So this is the way you define an ASP.NET web application build using VSTS.

Build Infrastructure
You have now seen a build in action, but how does this all work if it comes to the infrastructure we need? Let's have a look at the various options we have if it comes to using build agents and the terms used to define the build infrastructure. To start, we have a set of so called hosted agents. A hosted agent is an agent provided by Microsoft for which you pay per minute usage. Every VSTS account gets a set of free build minutes. You can buy additional build minutes inside the Azure portal. There are two options for buying additional build minutes. When you start buying build capacity, then the concept of a pipeline is important. This is because you either buy additional build minutes or you buy a so called hosted pipeline. A hosted pipeline will give you unlimited build minutes for one concurrent build. By buying more hosted pipelines, you buy more concurrent unlimited build minutes. The reasons these are called pipelines is because the agents are also used for release management. Both the build and the release are together a continuous delivery pipeline. If you only need some additional build minutes, then you can still buy additional build minutes. You always need to check the actual pricing since it constantly changes, but if you need at the moment more than 800 additional build minutes, you are better off buying a new hosted pipeline. The second option is that you're going to host the build agent on your own infrastructure. We call this a custom build agent. Remember that this agent is also used for release management. When you want a custom build agent, you can download the agent software and you can register this agent with VSTS. Every custom agent you register counts as a so called custom pipeline. Default you get one free custom pipeline. So if you want to host multiple custom build agents, you then need to buy additional private pipelines. Finally, we also have the notion of an interactive custom build agent. This is a build agent that you can configure to run interactive. This is a requirement if you want to run automated UI tests as part of your build or deployment pipeline. In order to run interactive tests, you need to have an interactive build agent to start a browser and interact with for example a website. This is also needed when you're running coded UI tests for example on UWP or client applications like Windows Forms. Interactive agents are always a custom build agent and they cannot be bought as a hosted option.

Build Security
When you set up to build infrastructure, then we need to manage the security of the build so we can ensure only those who have the correct access rights can start and manage the builds. This is managed by a security system surrounding builds. Let's have a closer look at how this works. We already defined the notion of a hosted or a custom build agent. The agent is a process that you can run on any machine that will execute the build on the machine it runs on. These agents are cross-platform, meaning you can run them on Mac OS, Windows, and Linux machines. The agent is a downloadable package that you can download from the TFS or VSTS configuration pages. When you download the agent, you need then to run the configuration process for that agent. This will then register the agent with your on-premises TFS server or the VSTS servers. During the configuration of an agent, you need to provide the name of a so called pool this agent will be part of. Agent pools are the virtual concept of a securable unit. You can define access to a pool and you can for example grant the rights to register new agents or remove agents from that pool. Default there are multiple pools on a TFS server or VSTS servers. The first pool is the default pool and this is where we register our own custom build agents. The default pool always contains your own custom agents. Default agents serve a specific purpose of running a build where you need predefined software on a specific machine, for example special capabilities such as special licensed software that needs to be on the machine. The other pools are hosted pools. This is a pool that contains agents that are provided by Microsoft and are running inside the Azure cloud as part of the VSTS service. Microsoft manages these machines and they manage the software that is available on those machines. These hosted agents are shared amongst all the users of the VSTS servers. Agent pools are exposed to a team project using agent queues. These queues are also a securable resource so you can restrict for example who can queue a new build. So it's now possible to define a pool that has a name of a specific location and you can restrict access to who can register an agent to that pool. You can also restrict access to a group of people who can queue a build on that specific pool by securing the agent queue. Let me show you in a demo how you can add a custom interactive agent on a virtual machine and use security mechanisms to define who can add agents to the pool.

Setting up a Custom Agent and Security
In this demonstration, I'm going to show you how you can set up a custom agent and add security to the pools. So we first go to the account settings and in the account settings, we're going to select the agent pools because there is where we can manage the pools that are available for our VSTS account. So here you see that I have the standard pools available so the hosted pools and my default pool where I can add a custom agent. You see here that I have an additional account which has less rights which is vriesmarcel1972. And if I go to the exact same location here, you see that I have the exact same view. You see that I have the hosted agents and I see here the Visual Studio agent that is available for Visual Studio 2017. But if I go all pools, you can see that I do not have enough access rights to define anything here in the agent pools because I just am a simple user. Now let's switch back to my admin account which is Marcel de Vries over here and now what I can do is I can go to all pools and I can specify that I would like to define a role for someone else. So here what I will do is I will add myself here which is the vriesmarcel1972 account and I will make that an administrator, giving me enough rights to define a new pool and add an agent to the pool. You see now that I inherit these rights for every pool immediately. And when I go to my other account again, you will see that I have enough access rights. So when I refresh this, you see now that I have access rights here and I can now define a new pool. So when I define here a new pool, let's call it a demo pool and I click OK, you see that I could create a new pool where I can add custom agents to myself. Now in order to add agents here, I need to download it and when I configure that agent, I need to have a personal access token. So let's go to my account and then add a new personal access token that I will use later on to add this agent to my new pool that I created. I will click on create token. This will generate an access token for me that I can use later and this is what I need to copy and I need to keep that safe because the moment I browse away from this window, that token will never be displayed again to me. This is now in my copy buffer and now what I can do is I can go back to the agent pools and I'll start downloading the agent. So we download the agent and you see that the agent is available for Windows, for OS X, and for Linux, so we can run it on any platform we want. We're going to choose Windows and I'm going to download it here, save it to my local machine, of course check if it's in the downloads folder so I can find it back, and once this is done, I can open that location. And the only thing that you need to do is you need to extract this. Just right click it and then extract it to some location. I will extract it to my demo location on my machine so C demo and then the agent name. Now we'll extract this and this just takes a couple of seconds. And the moment I've done this, you see now that I have a directory here. Let's go to my demo folder and here I can go to my agent folder and now we need to run the config command. Now the first thing I need to specify is the server URL. You might ask, "What is that server URL?" Well, that's the URL of the account that you want to connect this agent to. So in my particular case, that's fluentbytes.visualstudio.com, so we'll copy this URL and I can paste it in here. Be careful, it always needs to be HTTPS by the way. Now I can copy my token and paste it in here so I can authenticate with the server and now it asks me, "Where do you want to register to?" Well, we created this demo pool so I would like to register this agent to the demo pool of course so I'm going to specify that. Then I need to specify the name of the agent. I'm going to call it MyDemoVM and then it's going to scan for the tool capabilities. These are the demands that my agent can now satisfy. And then I need to specify a working folder. Now since I am on a virtual machine in Azure, there is always in Azure this D disk which is an SSD disk. This makes it very fast for the build so I'm going to specify a build folder on my D drive. I'm going to specify that I want to use D and then my build folder so it's always using the SSD disk. So now I'm not going to run as an interactive service and I'm not configuring autologon yet. This is what you need to do when you want to run interactive and want to run for example automated tests on this agent. So now you see that the agent is registered, but it is red because it's not running at the moment. It's at the moment offline. So now the next command I need to do is run. This will now again scan for the tool capabilities for the demands it can satisfy. Then it's connecting to the server and now it's listening for jobs. So now we should be able to see that this agent, since it's listening, should now be marked as green in my portal and here you see it's green so meaning that it's now accepting any jobs being queued to the agent. Now you can still specify additional options. You can for example specify some maintenance jobs and one of those maintenance jobs is for example to clean up your build folders so it's not eating up your hard drive all the time and you can specify a schedule for that and all those kind of things which is nice. You have some maintenance on your build agents done automatically. Every Sunday we're going to clean the disks for example. And here you can see the history of all the maintenance that's been done on your agent. So if you have strange behavior, you can check if some maintenance might have updated the agent for example. Now let's go and queue a build on this new agent that we have. So I go to my build tab, I go to my build definition, and in this build definition I can now say, "I would like to queue a new build, "but now I'm going to specify that I'm going to queue it "on my new agent." So instead of the hosted build, I'm now going to specify my demo pool and this will then automatically select the agent on my machine. So now you see that I queued the build and what you can see now is that it's running the job. Here you see running the job, meaning that it's now actually picking up the work that I scheduled to run on them. Now let's have a look at this build. You can see by the way that it's much, much faster as the hosted builds, but that's because I have a pretty fast machine now running in Azure and we are using the SSD disks which makes this extremely fast if it comes to disk I/O. So now you see the build succeeded and now we run it for 27 seconds only instead of the four minutes that we did in the past. You can see on my D drive that this is the artifacts that are being created and the results of my build. So with this, I've showed you how you can register a custom agent on a pool that we just created ourselves.

Continuous Integration with Visual Studio Team Services
Now that we know the fundamentals of setting up a build, let's have a look at how we can unlock the capability of the continuous integration build. This is what we defined at the start of this module. Let me just show you how simply this can be done in the following demo. In this demonstration, I'm going to show you how we can integrate Visual Studio Team Services using continuous integration. So when I go back to my build definition, I can now have a look at that definition and then see that I would like to integrate it with continuous integration. So for this, I can go to the triggers tab and on the triggers tab we will find the option to specify that we would like to enable continuous integration. Now the moment I click this, I get some options, for example the option that I would like to batch the changes when a build is already in progress so I'm not queuing more and more builds all the time. I can also set some branch filters so I'm only interested in parts of my repository or I can specify multiple branches so that I have the same build serving multiple branches. So as a good citizen, I am going to specify what I changed so I added the CI configuration here. I'm going to save this. And next I would like to go to my build tab and when I go to my build tab, first let me right click here and then open already a tab with the source code because I want to show you simultaneously what is going on. So let's go to the build definition here and you can now see that there is no build currently running. And what we're going to do is we're going to the tab I just opened and going to the source files, I'm just going to find a source file. Let's go to one of the controllers for example and in one of these controllers, let me just add some comments because when I would check that in, that would trigger a new build because I made some changes to the source code. So let's go here, click on the edit button so that I can edit here in line in my Git Repository and then just add some comments here, so for example the comment that I would like to trigger a build based on this comment that I'm going to provide. So next I'm going to click on commit. Of course, I can specify then what I'm doing here so I added some comments to trigger the build. And then the moment I click commit, you will see then that this... And by the way, I can select a work item if I would have one, but then I can click commit and the moment I click commit, this is now being picked up by the build and what we'll see is that automatically, a build is now in progress. And when I click this build, I can then see that the progress is what we expected. Now our default is still that we are going to use the hosted agents so it's going to wait on the hosted agent and it's going to run a build. Now let me take the next step because what I would like to do is show you that this also works when we're using another source control provider. So what I've done is I made it available also in GitHub so I have the same sources running on GitHub and you see that over here and this is also the ASP.NET MvcMusicStore. So it's exactly the same source code. And when I go here, I can then also go to the controllers and I would like to trigger again a build based on the fact that I'm going to make a change here to the home controller. Now let's go back to the build here and I need to set it up that it's now going to pick up the data from GitHub. So I'm going to log into my GitHub account, two-step authentication here. I'm going to grant access to my account here. Click OK here and now it has granted access. That means that now VSTS can pull some information from GitHub. So now I can select my repository. I've got a couple, but I'm going to select the build demo over here and I'm going to select the branch which will just be the master branch. There are no more branches here. I just have master here. And once this is set up, I can now save this one, so I'm not doing the save and queue but save it. And the moment I save it, of course I can have a look at the process and in the process what I will do is I will select the demo pool because that is a faster way of building things instead of using the hosted pool so again I'm going to save this, but now I also changed the definition so it's running on my pool that I just created myself with my custom agent which is way faster than the hosted one. Now let's save this and next I'm going to my GitHub page and I'm going to make an edit there. So let's go to the build definition here. We see that we don't have any builds running at the moment which is what we expect. We see over here just as we've seen with the VSTS Git integration. By the way, you see now here that I have the GitHub integration or the GitHub icon there. Now let's click on edit and I'm going to edit this file as well so I'm going here and add some comments. Let's type more or less the same comment that I would like to trigger the build here. And the next thing that I need to do is to click on commit changes. And the moment I commit these changes that's been saved at GitHub, that's the moment my build is being triggered and you see here already that I now have the automated builds running. So when I go here, you see of course that it's changed because it's now selecting MyDemoVM as the build agent. You see that it's triggered in getting the sources from GitHub. So with this, you've seen that we can run CI builds using VSTS from any source control provider available.

Summary
In this module, we have looked at the fundamentals of the Team Foundation Server or Visual Studio Team Services build. We first looked at the fundamentals of a build like the notion of a build definition, build steps or tasks, and the concepts of a build agent. Then we looked at setting up a build infrastructure and the components that are part of this infrastructure. You now should be able to set up your own build agents or use the hosted agents provided in the cloud. Next, we looked at the security of a build and how to set up the required permissions to register an agent and to queue build on a specific pool. We ended this module with setting up continuous integration on any of the provided source control integrations. In the next module, we will have a look at more details on the build things like build variables, retention policies, and the demands that you can specify so your agents are found with the correct capabilities before they start. We will look at tasks from the marketplace and we will look how to set up parallel builds and setting up builds using a very new concept called a YAML build. I hope to see you back in the next module.

Configuring More Specialized Builds
Introduction
Welcome back to the course Continuous Delivery and DevOps with TFS and VSTS 2018, Managing Builds. This is the module Configuring More Specialized Builds. In this module, I will show you all the details of configuring a build, and the various options you have to define more specialized and optimized builds for a specific purpose. My name is Marcel de Vries, and I'm the Pluralsight author of this course. Please don't hesitate to reach out to me on Twitter @marcelv or use the Pluralsight Discussion Forum when you still have questions unanswered when taking this course. I will try to help you as soon as possible.

Outline
We will start this module with looking at more details of build definitions. We will look at variables, triggers, options, and retention policies. Next we will have a look at the various build tasks that come out-of-the-box and are very frequently used. We'll also have a look at how we can manage credentials that are needed for certain tasks, and how we can manage these secrets. Then we will have a look at how we optimize your builds, and enabling parallel execution of certain parts of the build. Finally, we will conclude this module with looking at the brand-new concept introduced in 2018 called Yaml builds. Let's get started with the build details.

Build Details
By now you know how to set up the infrastructure and security of a build, now let's have a look at more details how to configure your build of your needs. Let's look at concepts like build variables, triggers, options, and retention. When you define a build, you have a set of tasks that get executed, and every task needs to be configured, so you need to punch in the data for every setting of that task. It is often the case that you have to repeat yourself over and over again, and therefore you can define variables. You can then assign the variable a value, and this variable can be used in the property that you need to set in a task. Once you define a variable in the Variable tab available in the build, you can then refer to the variable using the syntax: dollar sign, open parentheses, name of the variable, and then closing parentheses. There is also a set of predefined variables that can be used, for example, information on the current build agent, the working directories on the machine or the build number. There is a well-documented list of variables available. Sometimes you just want to execute a PowerShell script. In this script, you might determine information that you want to pass along to the build. For this, there is a special syntax that can be used as part of your script. So the build will pick it up, and the data becomes available as a variable that can be used further in the build steps of the build. You'll also often have variables that you want to treat as a secret. You can mark these variables as a secret, and this will ensure the real values of the variable will never be outputted to the Web UI, the logs, or any of the environment variables that get created. A final thing to note is that every variable you define and use in the build will become an environment variable during the build, except, of course, the secret ones. So if you have software that needs an environment variable set before it can operate properly, you just define a variable and it will become part of the environment before your program is executed as part of the build.

Build Triggers
Builds can have automated triggers, and the trigger you have available varies a bit based on the source control system you have selected to build your sources. For all source control systems, VSTS provides the concepts of a continuous integration trigger. This means the moment you commit or check-in the sources on the server, the build will be started. If you use the built-in Git solution as a source control system, then there is an additional option for the CI trigger, and that is that you can specify a so-called branch filter. This means that the build will only get triggered when the commit is inside of the definition of the branch filter. When using GitHub or the built-in Git source control provider, you also get the option to specify you want to build the sources on a pull request coming in. When using GitHub, then this is part of the build definition. When using the built-in Git solution, then this will become part of the branch policy you can set up. Then you can specify there which build you want to be triggered when the pull request gets in. When using Team Foundation Version Control, then there is an option to use this build as a guard of a branch. This is better known as a gated check-in. This means the moment someone tries to check in on a specific branch, a build will be triggered before the change _____ is accepted. If the build succeeds, based on the latest version and the shell set that is created, then the commit will be merged into the branch automatically. So all these triggers provide a great way to validate the sources that come into your source control system. This then ensures that your system is always buildable, and it will pass the specified tests that are part of your build.

Build Options
You also have some additional options you can specify. First you can specify the job properties. These are things like how long a job can take at a maximum before it gets killed, how long the server will wait on the cancellation of a build, and what the build has access to during the build. This can be the project collection, or it can be only your team project. The default is project collection, so default, a build has access to all the team projects in a project collection. You can also specify so-called demands. A demand specifies a specific capability you need for this build to succeed, for example, you need a specific product installed on the build machine before your build can succeed. In the build demand, you specify what is needed. The agent will specify its capabilities the moment it starts. When you queue a build, then the server will determine which agent is capable of running your build. It will find the first available agent and then schedules your build at that agent. If there is no agent that can build your software based on the demands you specified, then you will get a warning the moment you queue your build, since the possibility exists that this build will never actually run, since there's no agent that can satisfy the demands. Another thing that you can specify is, for example, the build number format. It is nothing more than a string specification on how you want the build to be build up based on certain numbers. You can specify here, for example, that you want the build numbers to be based on the date and time of the build server. You can also specify that the build will gather information on build completion, for example, work items that are part of this build. This is very convenient when you work with work items, and for example, create your branches from the work item cards. You have, for example, the option to create a branch for a specific card on the board, and from that moment on this work will be tracked against the branch. The moment you then run the build and the work item is completed, this then also implies that all the work that is part of the build is produced by this build. This information is very helpful for, for example, testers that can see if specified bugs are solved in a particular build. It is also very convenient for compliance reasons. Last but not least, you can specify you want to expose the so-called OAuth token for the build. This is handy for external processes to authenticate based on a token that is provided during the build. This token can then either be passed in as a variable, System.AccessToken, or it can be found as an environment variable that is set before the execution of any of your tasks. This is particularly handy for scripts and command line tasks that get executed and need to access VSTS during their execution.

Build Retention & History
The final thing we can specify is the retention policy of the build. Default this is set to the last 10 builds, and a minimum of one good build. It also specifies it keeps at maximum the build for 30 days, and 10 good builds. You can always override the retention policy for a specific build by marking the retention policy as retained indefinitely. This then circumvents the retention policy for the specific build. This is specifically done when a build is used in a release and the software is used by release management. The moment a release is scheduled, then the build is automatically set to retain indefinitely. When you make a change to the build definition, then it will be recorded in the build history. The build history will show you what has changed, by who, and it always gives you an audit trail what has been changed on the build.

Tasks and the Market Place
Default, you get a lot of tasks to build your software. You can easily search for tasks you need. Microsoft provides many tasks out-of-the-box. You can now build not only software from the Microsoft platform, there are a lot of tasks that will help you build non-Microsoft products like Node.js, Java, iOS, and Android applications. You can now build any software for any platform with the build agents running also on any platform, like the Mac, Linux, and Windows. If you can't find a task with a default search, you can also get the option to get tasks from open source and third parties that provide their tasks via the VSTS Marketplace. Also, when you run TFS on-premises you can still install those tasks on your on-premises TFS server. If that also fails, then there is this option to build your own tasks. There is a great SDK available that shows you how to build these tasks that can run on any platform. Let me show you in a demo where we can find a task in the Marketplace and use the options we already discussed.

Showing Build Details for Various Builds
In this demonstration, we're going to show you more build details, and how to install a task from the Marketplace. So let's go back to my build here, and let's go to the build definition. Now in my build definition I can show you some more details on what we could have configured. So first of all let's go to the Variables tab, and in the Variable tab I can add my own variables. If I go here to the bottom and click on Add, you can then type any name of the variable you want, you can then provide it a value that you want to use for all the tasks that then will use this variable. I can also specify a variable that is a secret variable, so I will call this MySecretValue. And I can specify it any value I want, and then by using the padlock icon on the right, I can then mark it as being a secret. Now you see now that it has been star, and the stars will all appear in the log, so nobody will ever see the secret anymore. Now here you see also the definition of a variable group, and I can link variables to multiple builds if I want to, so I can create a library of variables that I will use all over my builds. Now, the next thing that I can do is I can go to the Triggers. Now the triggers here you see that I connected this build up with GitHub, and it's now being specified as being a continuous integration build. And I can also specify that I would like to use this build for a pull request. So if I click this, then I can specify that every time a pull request comes in, this build will be used. I can also specify a schedule, and this schedule will be then any day of the week at a particular time that I want. And this one is particularly interesting. You specify if you want to run this build if nothing has changed in your repo, and that's very important if you want to, for example, use your build as a test if your stuff still works the moment you have, for example, Patch Tuesday. The other thing that we can do is we can specify the build job information, so we can specify here that I want, for example, the security to be set to be scoped to the current project instead of the project collection. We can set up how long a build may take, and it can set up how long I want to wait on a cancellation. I can also specify the demands. So if I need some special software installed on an agent, I can now specify this demand, and this agent needs to satisfy that demand before it will be selected for my builds. The final thing that we can do here is we can, of course, give it a description, and we can set the build number format. So we can specify, for example, that I would like to use semantic versioning instead of the date time that is default. The other thing that we can do is we can then temporarily disable a build and we can set here if we want to create work items the moment the build failed. I can even specify that I want to create a task instead of a bug, and the information will be in the task the moment it gets generated. Here you see the retention policies, you see the default is to keep a build for 10 days, and at least keep one good build all the time. And we can specify here if we're going to delete a build, for example, what needs to be deleted. So the files and some of the build artifacts, but for example, not the source label that we created. Now, if we look at these variables, I would like to see if these variables become part of my environment variable. So what I will do is I will add a new task to this build, so click on the plus sign here at Phase 1. And now what I can do is I can search for tasks, and I will search for a task, for example, PowerShell. So here we find the PowerShell task, I click on Add, and I will drag this PowerShell script up to one of my first tabs. And what I would like to do is I would like to dump out the environment variable, so I'm going to change this inline script, and I'm going to replace this inline Script with a simple script that will dump out all the environment variables, as you can see here, so that I can find that in my log, so I can show you later that every variable will be part of my environment the moment we run this build. the other thing we would like to do is we would like to specify what we're doing here with this script. So I'm specifying here that I'm going to dump the environment variables to the log so that it's now on the left-hand side visible what the task is actually doing, because just PowerShell script doesn't tell a lot. Now the other thing we would like to do is we would like to add a task that is going to replace some tokens, but that's not available default in your library, so we're going here to the Marketplace. Now in the Marketplace I can search for things, and one of the things that you see here is that we can have a task called Replace Tokens, which does exactly what I want, it will replace tokens that I have, for example, in my Web.config file or other locations. So I'm going to add this to my VSTS instance, and the next thing that I will do is I will then click on Proceed to my account, and the moment I proceed to my account, it will just go to the home page. Now the issues is when I search here for my new task, you will see that it's not available yet. So all we need to do is we need to save this build definition as it is now, then refresh my page, and then make the change a little bit later. So I'm going to save this here, of course, provide some good history information that we know that what we changed on this particular build, and now I can refresh my page, and the moment I have refreshed it, I can then again try to add a task, and when I search for it it will now become available, so Replace Tokens is now available and part of my build. So now I added to my build, I will place it before the build solution, because what I'm going to do is I'm not going to change any config files, I'm going to change the ch.html file because what I want is every time I see the MvcMusicStore, I want it to show me the version that I'm working on. So here you see the MvcMusicStore inside the GitHub, and what I do is I will go to my Shared Views, and to my Layout.cshtml, and here I can edit the page. So I click on the Edit icon here, and now on the bottom of the page I already specified a marker here that I can use. Let me scroll there, click there so that I can edit. Oops, it scrolls back again so let me go there again. And what I will do is I will specify between the markers __, that I want the build number to be shown here, so you see __build.BuildNumber, and then __, and this will be replaced now by the Replace Taokens task later in my build. So I'm going to commit these changes, and the moment I commit them I can then make some final changes to the build so that I can run the build and then replace those tokens later on. So let's go back to the build definition, and here in my task I will not search for a config file, but now I will search for a Layout.cshtml file, where I just place the markers. Now in my advanced configuration, I need to set it up that it understands my markers, and the default it has different ones than I'm going to use __ and __ as the postfix, so that way it will find my build number variable. By the way, every variable I specify in such a script that needs to be replaced is a variable that either I define or a system variable. In my particular case I'm using the build number which is just a system variable that is available during a build. Now let's save and queue this build, and see how this looks. Here we have the link available, so now we can have a look at the build, how it runs. Fortunately, it runs now on my custom agent so that will mean that it will run pretty fast, which is cool. And then once I'm done, we can have a look at the log files. Now here you see the dump environment Variables, and you see that the variables are shown in the log. And here you see now all the environment variables that become available. So here you see, for example, the build numbers that become available in part of my environment variables. Now if we scroll down, I should be able to see my custom variables. And if we look a little bit down here, here they are. So here you see my custom variable it has a value. Now note here that my secret variable is not available. You cannot see it here, which is a good thing, because otherwise it was not really a secret anymore. And here you see the Replace Token task which I got from the Marketplace, and here it replaced my token in the layout.cshtml file. So all seems to be pretty okay, so let's verify if my artifact actually changed, so that it really replaced a token, which I expected. So I go to the artifact folder, I'm going to download it, and the moment I have downloaded it, I can then extract the thing on my disk. So let's extract this on my local machine, and the moment I have it here I can then go into my Web Deploy package. So here is the drop folder, here you see the MvcMusicStore, which is now the Web Deploy package, I'm going to extract that one as well. And the moment that one is extracted, I can then go to the details, so go into the web deploy pack, and here we then finally see, it's a little bit deep here, but here we see my views, here I see the Shared view, here is my Layout file, and I'll open that with Notepad. And the moment I see there, we can scroll down, and if we scroll down we see that it's been replaced with the build number, so everything is as we expected. And with this I have shown you how we can customize the build, use all of the various build properties, and how we can add a task from the Marketplace and make that work in our build.

Optimize Your Builds
The builds are the heartbeat of your continuous delivery system. The reason I say this is because builds show you the status of the current product. It will show you if your product is in a buildable state, and it will show you if certain tests that you have run on the build artifacts have run successfully, and it prepares the artifacts you need to deploy them at any moment you want in time. So having a build up and running is something that you should strive for from the first day your product development starts. You should always strive for a constant green build, where a red build really indicates something bad and requires immediate attention for the team to fix. You should never have red builds for days and nobody caring. I think the builds green should be the number one priority of your team in order to be successful with continuous delivery. You should always strive for fast builds. Since thy provide such crucial information about the status of your product, you should also try to have the builds only take a couple of minutes to run. The longer the builds take, the harder it would be to fix the problems, and the more you team will suffer from a so-called broken window syndrome. That is, nobody cares if the build is broken, since it's always broken and it takes so much effort to fix. Speeding up your build starts with the right machines. Small VMs with relatively slow disks are a sure way to delay the feedback. Fast machines can make the difference between hours and minutes. When you're building your code, a lot of bits are moved across the wire, so inputs to the builds are fetched from a source control repository and the artifact repository such as the source code, NuGet packages, and node packages. In between, local deployments may be carried out, and shipping the results into other servers. And at the end, the output from the build process needs to be copied, the compiled artifacts, but also test reports, code coverage, and debug symbols. It is important that these copy actions are fast. Ensuring that the build server is located near the sources at a target location, can reduce the duration of your builds considerably. A single build server may suffice for a small product, but as the size and the scope of the product and the number of teams working on the product increases, a single server may not be enough. Scale your infrastructure horizontally over multiple machines when you reach the limit.

Different Builds for Different Purposes
Different builds can serve a different purpose. Often in projects we have at least three types of builds. First a CI build that triggers each commit in the source control repository, and it serves as the heartbeat of the project. Secondly, the nightly build. This build can take up some more time, because we need to do some extra steps to get additional information about our product, for example, metrics about the state of our software using SonarQube. It can also contain a set of regression tests and integration tests that validate a larger portion of the software. Finally, we have a release build. This build is there to provide the golden copy that will be pushed to the release pipeline to finally end up in the production environment. A release build is often triggered manually instead of a CI trigger. As you can see, each of these builds has a very specific purpose. The CI build ensures that a code compiles and provides quality feedback to the team. This ensures that the team is notified quickly when the code in the repository does not build anymore or has quality issues based on tests that show that some of the things are not working anymore. The scheduled build runs in the background and executes all the required quality tests. They may deploy the solution to a temporary machine to run the integration tests, and it can execute basic performance tests. If the team doesn't promote one of their scheduled builds through release management, then it may have the release build which additional compiles the API documentation, compliance reports, code signing, and other steps which are not required every time the code is built.

Optimizing the Build
The build can be optimized in many ways. We can, for example, add parallel build execution so we can speed up the build process. We can also enable parallel execution of test suites, which is often a huge time saver, especially when executing integration or UI tests. We can also use the notion of a multiplier, where we scale out our builds over multiple build agents. We can also move a part of the test feedback loop to the release pipeline. This then improves the build speed, and hence the speed of the build feedback loop. When we execute the tests that are above the unit test level to the release pipeline, and execute them in there in one of the early stages, then we get the best of both worlds, fast build execution and fast deployment verification using the integration tests. The other thing we can do to improve is that we publish the build artifacts to the package management system solution, and hence publish to a NuGet feed at the end of a build. Let me show you in the next demo how we can run multiple builds in parallel by setting the build face properties in the build definition.

Optimizing the Build to Run Parallel
In this demonstration, I'm going to show you how we can optimize the build by running in parallel. So first of all, we will go back to the build definition, and we will look at the build definition. I can then first go to the variables, and in the variables I will define a variable that we're going to use as the multiplier, so this will be the MultiPlier variable. And this MultiPlier variable needs to get some values, and we can specify a comma-separated list of values, and in my particular case I will use the variables 1,2,3. Now with 1,2,3, I can then specify that I want to use this as the build multiplier, and then every agent will get one particular build, one for value 1, one for value 2, and one for value 3. So I'm going to the Phase, the Agent phase, and on the Agent Phase I can now set that I would like to run in Multi-configuration mode. And here I define the Multiplier, which is then the variable, and the maximum number of agents that are allowed to run in parallel. Now by setting this up, I all of a sudden start three builds instead of one build at once, and every build will then be getting one of the values of the variable. So if I look at the Agent Queues, what I've done is I set up multiple build agents, so now you see that I have three agents running, instead of the one that we have been using all the time. So this gives me the option now to distribute the workload across these three agents, running the same builds, but for a different value of the variable. So let me go to the build, and let me now queue a new build. And when I queue the build, we will see in the results overview, so first go to the link, that we now have three builds that are getting started. So we see here in the build report already that it's a little bit different. You see now build number 1, and the build number 2 and number 3 running in parallel, and you see that all the builds are running on separate agents. So if I look here, you see that this one is on my DemoVM, if I look at the other one, you will see that it's running on the DemoVM2. So you see that there are different agents executing exactly the same build all the time. And this is a very convenient way of just speeding up your build. Instead of running three separate builds, we now run just one build, but we are distributed over three different agents. And with this, I've shown you how we can run multiple builds in parallel.

Yaml Based Builds
It is now also possible to define a build in your source control system as code. The idea behind this concept is that everything you do in you're application is just kept in source control. This includes the definition of your build steps and all the configuration. This way you should be able to go back in history and always be able to build the old version of the software with the definition you also used in that timeframe. It nicely aligns with the concept of continuous delivery, like configuration and Infrastructure as Code. This is now more or less the addition of the concept Build as Code. The way this works is that you specify a build in a file format called Yaml. Yaml is used a lot more these days. You will also find Yaml files when working with containers, container clusters, and Docker. Yaml is a markup language that is a superset of JSON. Yaml has significant whitespace, so you need to be careful when editing these files. There is an option to convert your existing build build definition to a Yaml file. This is a great starting place to start your first exploration of Yaml builds. Let me show you in the following demo how we can run a simple Yaml-based build.

Show a Yaml Build
In this demonstration, I'm going to show you how we can use Yaml builds. So here we are back in our build, and where we will go is we will go to the Builds tab, and here I have my build overview where I can add a new build definition. So let's create a new build definition, and if we look at the templates that we have available, you see now at the top here that we have this notion of a Yaml build. So first what I will do is I will give it another name. I will give it the name that this is a Yaml build, YamlDemo. And the next thing that I need to specify is the Pool. So we will pick our DemoPool with the past agents, and then I go to my version control repository where I can select the Yaml file that I want. Now what I have done is, in my source repository I created a YamlBuild definition. So here you see that I have one step that I will do, and that is the step of dumping my environment variables. So here I go, and I select my Yaml-based build, and once this is done, I can then say, okay, get the sources. I will get the sources from my standard source control system, and now save and queue this. And we'll queue it on my DemoPool, and when I go and look at a definition here, just browse here, you'll see that the build is already running, and it's even finished already. It's pretty fast because we're only dumping the variables, right? So here you see the build stack that I executed, and here you see the exact same thing that we've seen in the previous builds where I'm dumping out my environment variables. Now this is, of course, a very simplistic Yaml build that we've done, and this is also something that is currently under heavy development, so we will see some different experience there in the future. But what we can do is we can also say, well, I would like to have a more extensive build. And the cool thing is that if you go and edit a current build definition that is available, so let's for example take our build that we already have been working on for quite a while, we can now click the view YamlBuild button. And this will give us a definition of Yaml that we can then copy out and paste and modify so that we then have a build that we can use in the future. And with this, I've shown you how we can use VSTS Yaml builds.

Summary
In this module, we looked at the details of a build. I showed you how to further configure the builds, and use concepts like variables, and additional options and triggers you can use to start a build. Next we defined where we can get the tasks we need to build our software. We either get them out-of-the-box, or we can get them from the Marketplace. We can even build our own using the cross-platform SDK, using cross-platform agents. We then looked at how we can optimize our builds, and also run them in parallel, or on multiple agents at the same time. We concluded this module with looking at an option to use build definitions from the source control repository in the form of Yaml files. By now, you should be able to build any type of software using the VSTS build system. You have seen it can get the sources from many places and build artifacts using many different tasks and options. In the last module of this course, we'll have a look at getting the required artifacts, including the provisioning scripts to a central location where we can then hand them off to release management. I hope to see you back in the next module.

Configuration and Infrastructure as Code
Introduction
Welcome back to the course Continuous Delivery and DevOps with TFS and VSTS 2018, Managing Builds. This is the module, Configuration and Infrastructure as Code. In this module, we'll have a look at how we can assure our delivery process will always behave the same. We do this primarily by eliminating the human factor in the process. We'll do this also for the configuration of our application and the provisioning of the required infrastructure. The fact we create the code to configure and provision environments is these days known as Configuration and Infrastructure as Code. My name is Marcel de Vries, and I'm the Pluralsight author of this course. Please do not hesitate to reach out to me on Twitter @marcelv or use the Pluralsight discussion forum when you still have questions unanswered when taking this course. I will try to help you as soon as possible.

Outline
We will start this module by looking at Configuration as Code. Next, we will have a look at how we can ensure that we securely configure our application and provide the correct values for secrets in a secure and easy manageable way. Then we will have a look at Infrastructure as Code as the way of ensuring we have a clean and exact same system every time we deploy our software. We finish this module by looking at the notion of an artifact repository, which is also part of VSTS. Let's get started with Configuration as Code.

Configuration as Code
Configuration as Code is an important concept in continuous delivery. In continuous delivery, we strive to build the automation to bring our software to production at any time of the day we want. For this to succeed, we need to have a very stable, robust, and reliable system to get our changes to production. One of the things that go often wrong is getting the correct configuration in place for the various environments we deploy our software to. Most of the time, this is still a manual task. Configuration as Code defines that we keep our configuration as part of the configuration management solution, which is most of the time a source control system like TFVC, subversion or Git. With Configuration as Code, we keep our configuration artifacts like Web.config file for ASP.NET or XML and JSON configuration files, as part of our source control system. We then use our build system to output the correct files that we need for installation and configuration of our tests and production environments.

Transform Configuration
When we define our configuration in our source control system, we run into the issue that we do not want to store secrets in our source control system, especially not when this is a public repo at, for example, GitHub. We also want these secrets to be managed by special authorized people. Only they should be able to change and access this information. Therefore, we need to wait to separate the concerns of managing the secrets and generating the correct configuration artifacts for our deployments. In VSTS, we can make this work by using configuration transformations. So how do we make this work? First you need to define a set of variables that you know will contain secrets, and that you don't want to keep in source control. This set of variables is then given to the administrator, and he can then log on to VSTS and define the variables with the correct values. These variables are then marked as a secret, meaning others in the project can access them, but never read the actual values. It will also prevent this data to leak into log files and reports. Next we define a step in our build that can replace placeholders that we add to our configuration by actual values that are the variables defined by our administrator. To transform these placeholders in our configuration, we can use the Replace Tokens task. I personally prefer a task from the Marketplace in favor for the one default provided by Microsoft, since the one in the Marketplace also picks up the system defined variables out-of-the-box. With this task installed and added to our build, we can then generate the correct configuration during the build. The final step is done to place this in the artifact repository, where it can be picked up by our release management tools.

Infrastructure as Code
The final important part of a deployment that is often forgotten is that the software we produce requires a large set of prerequisites in order to work properly. This can be settings on the production machine like locale settings, language settings, or the availability of certain features or firewall rules, or perhaps even the requirement of additional third-party software that our software relies on. This preparation of the target environment required by our product is referred to as the infrastructure needed in order to function according to plan. When we also put this in source control and manage this to be prepared for execution by the build, we refer to this as Infrastructure as Code. With continuous delivery, we need to ensure that during the deployment process all the prerequisites are met, otherwise, our process is not reliable or repeatable. So we need to include all the artifacts that will help us set up the prerequisites for our application to run. On the Windows platform, you'll probably do this with tools like PowerShell, PowerShell DSC, and ARM templates. You will use Azure Resource Manager templates to provision machines on Azure or on your on-premises Azure stack solution. You will use PowerShell DSC to configure your Windows environment as needed without the need of scripting the whole installation yourself. With DSC, you can declaratively define what you need in terms of Windows features to be turned on, and the DSC will ensure that no matter what the preconditions are, it will execute the required scripts. Finally, PowerShell is the universal tool to ensure that anything else is okay on your machine. Although you can do all with PowerShell itself, it's recommended to use ARM for provisioning, DSC to get the service into the right state, and PowerShell to do certain tweaks to the machine that are not possible with ARM or DSC. If you're deploying to a non-Windows environment, you should set up your machine provisioning and configuration using additional tools or products like Chef, Puppet, and Bash. The most important part here is that there's never any manual tweaking of a machine before we deploy our software, so everything needs to be scripted. This ensures our process is reliable and fully automated, conforming to continuous delivery principles.

Artifact Location
Now that we know that we want all our configuration and infrastructure defined in files and scripts, how do we deal with this in our builds and releases? For this, there is an important place called the artifact repository. This is something provided default by VSTS. So let's see how we can get our data to this location so that we are ready to trigger an automated release. During our builds, we always want to add a step to the build process to publish the artifacts we have to an artifact repository. This is the starting point of any release we will do based on our builds. TFS and VSTS have a built-in artifact repository, and we can copy the artifacts that come from the builds to this location. For this, there is a specific build task called Publish Artifacts, and we can select the option server or files here. I most of the time use the server since that's the most easy way to set it up. Now one of the things that we need to do is that we need to copy the infrastructure and configuration scripts we need, and make that part of the build's drop. This way our scripts are always part of the same build, and we have a consistent and versioned way of moving our products forward in the pipeline. Let me show you in the next demo how this can be done.

Adding Configuration and Infrastructure as Code to Your Build
In this demonstration, I'm going to show you how we can add configuration and infrastructure as code to our build. So the first thing that we'll do is that we'll go to the Azure portal because I want to create a new Azure web app. So first I need to log into the website, and now I can go to the App Services tab to create a new app service, which will be a web application that I can deploy to. So I click on Add, and I will just select a simple web application. Now I can click on Create, provide it information like its name, and then I can go to the Automation properties, and I can download the automation to do this from another location than the Azure portal. So what I do is I will download it, and download it to my local machine, and it will open the zip file that I get. Now if you extract the zip file, you will see that you get a bunch of files, some of them are PowerShell, and some of them are in another language format. I also like the deploy, file, the parameters file, and the template, and those three will be added to my source control repository. So I'll copy these over, and I will go to my source control repository, which is a Git on my local machine. So I go to Users, my name, then find the repo, and in the repo I can then go to a folder that I already created calledPprovisioning. Now I want to provision my web application, so I go to WebApp and I will paste in these additional file that I will then add to Git. So for this I need to start a command prompt, and now I can use the command git add. And next I need to commit this to my repository, git commit, provide it, of course, a nice message that I'm adding at the moment, configuration and infrastructure as code. Now this is committed, so the final thing I need to do is push this, and I push this to the remote github, because I have two remotes on this specific repository. So now it should be in GitHub, so let's check if the files are there. And when I browse through my repository, you can see that I go to the Provisioning location, WebApp, and here you see that I have the various files. So now everything is in source control, so next what I can do is change my build to include those files as a build output artifact. So what I need to do is add an additional step because Publish Artifacts is already part of my current build. It's part of the default template, so that's the reason it's in there. And I will add an additional step to copy files to my local staging artifact directory, which will then be published later. So here I move it up before the Publish Artifacts. I will now select the files that can be found in my repository, here you can see them, so that's the rude location. And what I will do is I will get everything from there and move that to the artifact directory that's used for staging. So once this is done, I can now say Save & queue. I can queue a new build, and now what should happen is it should now pool these artifacts that I have in my artifact repository, and then move them to the artifacts repository. And I did not include the Replace Tokens here because I already did that in the previous module. You can, of course, imagine that if you have set up some variables, you can now add markers to, for example, the parameters file, and based on that get specific names that you want in there defined by your administrator. So now we see that the build has finished, and once it's finished we can then have a look at what are the artifacts that are part of this build. So we'll go to the Home screen, see the report, go to the Artifacts repository. Here I can then explore the repository, and if all is well, I now see that my files became part of the build output. And this is the starting point for a release that we can do with release management. And with this, I've shown you how we can add Configuration and Infrastructure as Code as part of our builds.

Summary
In this module, we have discussed the concept of Configuration as Code as a way to improve our continuous delivery process. We then looked at the way we can transform configuration in such a way that we separate concerns and have a secure way of producing the artifacts required. We then looked at Infrastructure as Code, and finally, we looked at how we can get all the configuration and infrastructure required in the Artifacts store, so we can hand them off to the release process. With this we came to the end of this course. I hope you learned a lot and enjoyed it. Please do not hesitate to reach out to me on Twitter @marcelv or use the Pluralsight discussion forum when you have still questions unanswered. I will try to help you as soon as possible.